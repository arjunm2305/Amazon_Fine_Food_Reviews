{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier on Amazon Food Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet Source: https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Necessary Python Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Bow data:\n",
    "import pickle\n",
    "with open('train_bow.pickle','rb') as handle:\n",
    "    train_bow = pickle.load(handle)\n",
    "with open('test_bow.pickle','rb') as handle:\n",
    "    test_bow = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Tfidf data:\n",
    "import pickle\n",
    "with open('train_tfidf.pickle','rb') as handle:\n",
    "    train_tfidf = pickle.load(handle)\n",
    "with open('test_tfidf.pickle','rb') as handle:\n",
    "    test_tfidf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg Word2Vec data:\n",
    "import pickle\n",
    "with open('train_avg_word2vec.pickle','rb') as handle:\n",
    "    train_avg_word2vec = pickle.load(handle)\n",
    "with open('test_avg_word2vec.pickle','rb') as handle:\n",
    "    test_avg_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg Word2Vec data:\n",
    "import pickle\n",
    "with open('train_tfidf_word2vec.pickle','rb') as handle:\n",
    "    train_tfidf_word2vec = pickle.load(handle)\n",
    "with open('test_tfidf_word2vec.pickle','rb') as handle:\n",
    "    test_tfidf_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('y_train.pickle','rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "with open('y_test.pickle','rb') as handle:\n",
    "    y_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('y_train_w.pickle','rb') as handle:\n",
    "    y_train_w = pickle.load(handle)\n",
    "with open('y_test_w.pickle','rb') as handle:\n",
    "    y_test_w = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "#Bow features\n",
    "train_bow_normalize = normalize(train_bow, axis=0)\n",
    "test_bow_normalize = normalize(test_bow, axis=0)\n",
    "#Tfidf Features\n",
    "train_tfidf_normalize = normalize(train_tfidf, axis=0)\n",
    "test_tfidf_normalize = normalize(test_tfidf, axis=0)\n",
    "#Avg word2Vec Features\n",
    "train_avgw2v_normalize = normalize(train_avg_word2vec, axis=0)\n",
    "test_avgw2v_normalize = normalize(test_avg_word2vec, axis=0)\n",
    "#Tfidf Weighted Word2Vec\n",
    "train_tfidfw2v_normalize = normalize(train_tfidf_word2vec, axis=0)\n",
    "test_tfidfw2v_normalize = normalize(test_tfidf_word2vec, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of b is 12.\n",
      "The misclassification error for each 'b' value is :  [0.1971 0.2386 0.1379 0.1594 0.1386 0.1427 0.1341 0.1274 0.128  0.1287\n",
      " 0.1264 0.1213 0.1241 0.1236 0.1247 0.1233 0.124  0.1243 0.123  0.1231\n",
      " 0.1273 0.125  0.1254 0.1234 0.1216 0.125  0.1251 0.1221 0.1251]\n"
     ]
    }
   ],
   "source": [
    "#Creating No of BaseLearners List.\n",
    "baseLearners = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for b in baseLearners:\n",
    "    RF = RandomForestClassifier(n_estimators=b,n_jobs=-1)\n",
    "    scores = cross_val_score(RF, train_bow_normalize, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "#Determining best No of base Learners.\n",
    "optimal_b = baseLearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of b is %d.' % optimal_b)\n",
    "\n",
    "print(\"The misclassification error for each 'b' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the RandomForest Classifier is 85.733333%\n",
      "(array([0.70048309, 0.86895811]), array([0.28375734, 0.9750904 ]), array([0.40389972, 0.91897009]), array([ 511, 2489], dtype=int64))\n",
      "[[ 145  366]\n",
      " [  62 2427]]\n"
     ]
    }
   ],
   "source": [
    "#Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=optimal_b,n_jobs=-1)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_bow_normalize, y_train)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_bow_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test, predicted) * 100\n",
    "print('\\nThe accuracy of the RandomForest Classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Featurization: Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of b is 16.\n",
      "The misclassification error for each 'b' value is :  [0.1836 0.234  0.1437 0.1506 0.1293 0.1374 0.1299 0.1271 0.128  0.1263\n",
      " 0.1271 0.1243 0.1287 0.1254 0.1266 0.1206 0.129  0.1274 0.1251 0.123\n",
      " 0.1281 0.1253 0.1263 0.127  0.1263 0.122  0.1259 0.1246 0.1253]\n"
     ]
    }
   ],
   "source": [
    "#Creating No of BaseLearners List.\n",
    "baseLearners = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for b in baseLearners:\n",
    "    RF = RandomForestClassifier(n_estimators=b,n_jobs=-1)\n",
    "    scores = cross_val_score(RF, train_tfidf_normalize, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "#Determining best No of base Learners.\n",
    "optimal_b = baseLearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of b is %d.' % optimal_b)\n",
    "\n",
    "print(\"The misclassification error for each 'b' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the RandomForest Classifier is 85.300000%\n",
      "(array([0.65350877, 0.86940837]), array([0.29158513, 0.96826035]), array([0.40324763, 0.91617563]), array([ 511, 2489], dtype=int64))\n",
      "[[ 149  362]\n",
      " [  79 2410]]\n"
     ]
    }
   ],
   "source": [
    "#Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=optimal_b,n_jobs=-1)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_tfidf_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test, predicted) * 100\n",
    "print('\\nThe accuracy of the RandomForest Classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Avg Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of b is 27.\n",
      "The misclassification error for each 'b' value is :  [0.2333 0.302  0.1806 0.2091 0.1684 0.183  0.1579 0.1676 0.1567 0.1623\n",
      " 0.148  0.1539 0.1476 0.1509 0.1469 0.1497 0.1477 0.1481 0.146  0.1444\n",
      " 0.1437 0.1429 0.1446 0.1454 0.1454 0.1476 0.1421 0.1434 0.1449]\n"
     ]
    }
   ],
   "source": [
    "#Creating No of BaseLearners List.\n",
    "baseLearners = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for b in baseLearners:\n",
    "    RF = RandomForestClassifier(n_estimators=b,n_jobs=-1)\n",
    "    scores = cross_val_score(RF, train_avgw2v_normalize, y_train_w, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "#Determining best No of base Learners.\n",
    "optimal_b = baseLearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of b is %d.' % optimal_b)\n",
    "\n",
    "print(\"The misclassification error for each 'b' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the RandomForest Classifier is 80.800000%\n",
      "(array([0.20183486, 0.83085438]), array([0.04305284, 0.9650462 ]), array([0.07096774, 0.8929368 ]), array([ 511, 2489], dtype=int64))\n",
      "[[  22  489]\n",
      " [  87 2402]]\n"
     ]
    }
   ],
   "source": [
    "#Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=optimal_b,n_jobs=-1)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_avgw2v_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test_w, predicted) * 100\n",
    "print('\\nThe accuracy of the RandomForest Classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test_w, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test_w, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Tfidf Weighted Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of b is 29.\n",
      "The misclassification error for each 'b' value is :  [0.2321 0.2996 0.1839 0.2103 0.1617 0.1837 0.1607 0.1646 0.1521 0.1586\n",
      " 0.1486 0.1556 0.1504 0.1501 0.1491 0.1481 0.1446 0.1473 0.1451 0.1451\n",
      " 0.145  0.1461 0.1479 0.1439 0.1437 0.1426 0.143  0.1441 0.1407]\n"
     ]
    }
   ],
   "source": [
    "#Creating No of BaseLearners List.\n",
    "baseLearners = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for b in baseLearners:\n",
    "    RF = RandomForestClassifier(n_estimators=b,n_jobs=-1)\n",
    "    scores = cross_val_score(RF, train_tfidfw2v_normalize, y_train_w, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "#Determining best No of base Learners.\n",
    "optimal_b = baseLearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of b is %d.' % optimal_b)\n",
    "\n",
    "print(\"The misclassification error for each 'b' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the RandomForest Classifier is 80.500000%\n",
      "(array([0.19672131, 0.83078527]), array([0.04696673, 0.96062676]), array([0.07582938, 0.89100056]), array([ 511, 2489], dtype=int64))\n",
      "[[  24  487]\n",
      " [  98 2391]]\n"
     ]
    }
   ],
   "source": [
    "#Create a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=optimal_b,n_jobs=-1)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_tfidfw2v_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test_w, predicted) * 100\n",
    "print('\\nThe accuracy of the RandomForest Classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test_w, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test_w, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BoW---------->BaseLearners=12 ---------->Acc=85.73%\n",
    "* Tfidf---------->BaseLearners=16 ----------->Acc=85.30%\n",
    "* Avg Word2Vec--------->BaseLearners=27---------->Acc=80.80%\n",
    "* Tfidf Word2Vec---------->BaseLearners=29---------->Acc=80.5%\n",
    "* Bag of words featurization gives highest Accuracy with 12 baseLearners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
