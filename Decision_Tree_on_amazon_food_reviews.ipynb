{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier on Amazon Fine Food Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet Source: https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Bow data:\n",
    "import pickle\n",
    "with open('train_bow.pickle','rb') as handle:\n",
    "    train_bow = pickle.load(handle)\n",
    "with open('test_bow.pickle','rb') as handle:\n",
    "    test_bow = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Tfidf data:\n",
    "import pickle\n",
    "with open('train_tfidf.pickle','rb') as handle:\n",
    "    train_tfidf = pickle.load(handle)\n",
    "with open('test_tfidf.pickle','rb') as handle:\n",
    "    test_tfidf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg Word2Vec data:\n",
    "import pickle\n",
    "with open('train_avg_word2vec.pickle','rb') as handle:\n",
    "    train_avg_word2vec = pickle.load(handle)\n",
    "with open('test_avg_word2vec.pickle','rb') as handle:\n",
    "    test_avg_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg Word2Vec data:\n",
    "import pickle\n",
    "with open('train_tfidf_word2vec.pickle','rb') as handle:\n",
    "    train_tfidf_word2vec = pickle.load(handle)\n",
    "with open('test_tfidf_word2vec.pickle','rb') as handle:\n",
    "    test_tfidf_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('y_train.pickle','rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "with open('y_test.pickle','rb') as handle:\n",
    "    y_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('y_train_w.pickle','rb') as handle:\n",
    "    y_train_w = pickle.load(handle)\n",
    "with open('y_test_w.pickle','rb') as handle:\n",
    "    y_test_w = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "#Bow features\n",
    "train_bow_normalize = normalize(train_bow, axis=0)\n",
    "test_bow_normalize = normalize(test_bow, axis=0)\n",
    "#Tfidf Features\n",
    "train_tfidf_normalize = normalize(train_tfidf, axis=0)\n",
    "test_tfidf_normalize = normalize(test_tfidf, axis=0)\n",
    "#Avg word2Vec Features\n",
    "train_avgw2v_normalize = normalize(train_avg_word2vec, axis=0)\n",
    "test_avgw2v_normalize = normalize(test_avg_word2vec, axis=0)\n",
    "#Tfidf Weighted Word2Vec\n",
    "train_tfidfw2v_normalize = normalize(train_tfidf_word2vec, axis=0)\n",
    "test_tfidfw2v_normalize = normalize(test_tfidf_word2vec, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of d is 8.\n",
      "The misclassification error for each 'd' value is :  [0.1447 0.1436 0.1377 0.1341 0.1311 0.1303 0.1283 0.1259 0.126  0.127\n",
      " 0.1271 0.1284 0.1289 0.13   0.1334 0.1326 0.1339 0.1349 0.1364 0.1373\n",
      " 0.138  0.1391 0.1411 0.142  0.1413 0.1417 0.1429 0.1449 0.1431]\n"
     ]
    }
   ],
   "source": [
    "#Creating list of depths for DecisionTrees\n",
    "depthList = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for d in depthList:\n",
    "    DT = DecisionTreeClassifier(max_depth=d)\n",
    "    scores = cross_val_score(DT, train_bow_normalize, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "#Determining best alpha\n",
    "optimal_d = depthList[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of d is %d.' % optimal_d)\n",
    "\n",
    "print(\"The misclassification error for each 'd' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the DT classifier is 84.566667%\n",
      "(array([0.65584416, 0.85593816]), array([0.19765166, 0.97870631]), array([0.3037594 , 0.91321462]), array([ 511, 2489], dtype=int64))\n",
      "[[ 101  410]\n",
      " [  53 2436]]\n"
     ]
    }
   ],
   "source": [
    "#Create a DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=optimal_d)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_bow_normalize, y_train)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_bow_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test, predicted) * 100\n",
    "print('\\nThe accuracy of the DT classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Featurization: Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of d is 9.\n",
      "The misclassification error for each 'd' value is :  [0.1451 0.1417 0.1377 0.1359 0.1311 0.1303 0.129  0.128  0.1269 0.1271\n",
      " 0.128  0.1304 0.1309 0.1287 0.1311 0.1301 0.1341 0.1349 0.1363 0.1363\n",
      " 0.1377 0.1401 0.1409 0.1411 0.1434 0.1441 0.1431 0.1464 0.1464]\n"
     ]
    }
   ],
   "source": [
    "#Creating list of depths for DecisionTrees\n",
    "depthList = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for d in depthList:\n",
    "    DT = DecisionTreeClassifier(max_depth=d)\n",
    "    scores = cross_val_score(DT, train_tfidf_normalize, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "#Determining best alpha\n",
    "optimal_d = depthList[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of d is %d.' % optimal_d)\n",
    "\n",
    "print(\"The misclassification error for each 'd' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the DT classifier is 84.966667%\n",
      "(array([0.66666667, 0.86134752]), array([0.23483366, 0.97589393]), array([0.34732272, 0.91504992]), array([ 511, 2489], dtype=int64))\n",
      "[[ 120  391]\n",
      " [  60 2429]]\n"
     ]
    }
   ],
   "source": [
    "#Create a DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=optimal_d)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_tfidf_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test, predicted) * 100\n",
    "print('\\nThe accuracy of the DT classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Avg Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of d is 1.\n",
      "The misclassification error for each 'd' value is :  [0.1444 0.1444 0.1463 0.1506 0.1526 0.1621 0.1701 0.1786 0.1827 0.1874\n",
      " 0.194  0.198  0.1981 0.2071 0.211  0.2157 0.2174 0.2216 0.2199 0.225\n",
      " 0.2217 0.2233 0.2267 0.2266 0.226  0.225  0.2294 0.2234 0.2254]\n"
     ]
    }
   ],
   "source": [
    "#Creating list of depths for DecisionTrees\n",
    "depthList = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for d in depthList:\n",
    "    DT = DecisionTreeClassifier(max_depth=d)\n",
    "    scores = cross_val_score(DT, train_avgw2v_normalize, y_train_w, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "#Determining best alpha\n",
    "optimal_d = depthList[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of d is %d.' % optimal_d)\n",
    "\n",
    "print(\"The misclassification error for each 'd' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the DT classifier is 82.966667%\n",
      "(array([0.        , 0.82966667]), array([0., 1.]), array([0.        , 0.90690472]), array([ 511, 2489], dtype=int64))\n",
      "[[   0  511]\n",
      " [   0 2489]]\n"
     ]
    }
   ],
   "source": [
    "#Create a DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=optimal_d)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_avgw2v_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test_w, predicted) * 100\n",
    "print('\\nThe accuracy of the DT classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test_w, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test_w, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Tfidf Weighted Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value of d is 1.\n",
      "The misclassification error for each 'd' value is :  [0.1444 0.1444 0.1446 0.1483 0.1511 0.1581 0.1649 0.1674 0.176  0.1846\n",
      " 0.1871 0.1896 0.1984 0.2009 0.2003 0.2049 0.2076 0.2087 0.2181 0.2154\n",
      " 0.2111 0.2119 0.2193 0.216  0.2179 0.2156 0.2164 0.2183 0.2221]\n"
     ]
    }
   ],
   "source": [
    "#Creating list of depths for DecisionTrees\n",
    "depthList = list(range(1,30))\n",
    "#Empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "#Perform 10-fold cross validation\n",
    "for d in depthList:\n",
    "    DT = DecisionTreeClassifier(max_depth=d)\n",
    "    scores = cross_val_score(DT, train_tfidfw2v_normalize, y_train_w, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "#Determining best alpha\n",
    "optimal_d = depthList[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal value of d is %d.' % optimal_d)\n",
    "\n",
    "print(\"The misclassification error for each 'd' value is : \", np.round(MSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The accuracy of the DT classifier is 82.966667%\n",
      "(array([0.        , 0.82966667]), array([0., 1.]), array([0.        , 0.90690472]), array([ 511, 2489], dtype=int64))\n",
      "[[   0  511]\n",
      " [   0 2489]]\n"
     ]
    }
   ],
   "source": [
    "#Create a DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=optimal_d)\n",
    "#Train the model using the training sets \n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "#Predict Output \n",
    "predicted= model.predict(test_tfidfw2v_normalize)\n",
    "#Evaluate accuracy based on y_test and predicted.\n",
    "acc = accuracy_score(y_test_w, predicted) * 100\n",
    "print('\\nThe accuracy of the DT classifier is %f%%' % (acc))\n",
    "pre = precision_recall_fscore_support(y_test_w, predicted)\n",
    "print(pre)\n",
    "conf_matrix = confusion_matrix(y_test_w, predicted)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
