{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on Amzon Fine Food Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet Source: https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing all Necessory Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Bow data.\n",
    "import pickle\n",
    "with open('train_bow.pickle','rb') as handle:\n",
    "    train_bow = pickle.load(handle)\n",
    "with open('test_bow.pickle','rb') as handle:\n",
    "    test_bow = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Tfidf data.\n",
    "import pickle\n",
    "with open('train_tfidf.pickle','rb') as handle:\n",
    "    train_tfidf = pickle.load(handle)\n",
    "with open('test_tfidf.pickle','rb') as handle:\n",
    "    test_tfidf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg word2vec\n",
    "import pickle\n",
    "with open('train_avg_word2vec.pickle','rb') as handle:\n",
    "    train_avg_word2vec = pickle.load(handle)\n",
    "with open('test_avg_word2vec.pickle','rb') as handle:\n",
    "    test_avg_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Tfidf Word2Vec.\n",
    "import pickle\n",
    "with open('train_tfidf_word2vec.pickle','rb') as handle:\n",
    "    train_tfidf_word2vec = pickle.load(handle)\n",
    "with open('test_tfidf_word2vec.pickle','rb') as handle:\n",
    "    test_tfidf_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is ouput is for Bow and Tfidf\n",
    "with open('y_train.pickle','rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "with open('y_test.pickle','rb') as handle:\n",
    "    y_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for Avg word2vec and tfidf word2vec\n",
    "with open('y_train_w.pickle','rb') as handle:\n",
    "    y_train_w = pickle.load(handle)\n",
    "with open('y_test_w.pickle','rb') as handle:\n",
    "    y_test_w = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "#Feature Normalization.\n",
    "#Bow features\n",
    "train_bow_normalize = normalize(train_bow, axis=0)\n",
    "test_bow_normalize = normalize(test_bow, axis=0)\n",
    "#Tfidf Features\n",
    "train_tfidf_normalize = normalize(train_tfidf, axis=0)\n",
    "test_tfidf_normalize = normalize(test_tfidf, axis=0)\n",
    "#Avg word2Vec Features\n",
    "train_avgw2v_normalize = normalize(train_avg_word2vec, axis=0)\n",
    "test_avgw2v_normalize = normalize(test_avg_word2vec, axis=0)\n",
    "#Tfidf Weighted Word2Vec\n",
    "train_tfidfw2v_normalize = normalize(train_tfidf_word2vec, axis=0)\n",
    "test_tfidfw2v_normalize = normalize(test_tfidf_word2vec, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. GridSearchCV_L2-Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.874\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regressiojn with Grid search cv L2 regularization.\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "tuned_parameters = [{'alpha':[10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]}]\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_bow_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. GridSearchCV_L1-Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8553333333333333\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with GridSearchCV L-1 Regulizor.\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_bow_normalize, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863\n",
      "12057\n"
     ]
    }
   ],
   "source": [
    "#Look at how Sparsity and performance changing for the given C(here alpha).\n",
    "LR = SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42, alpha=0.01)\n",
    "LR.fit(train_bow_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_bow_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "12057\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42, alpha=0.1)\n",
    "LR.fit(train_bow_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_bow_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1.0)\n",
    "LR.fit(train_bow_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_bow_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=10)\n",
    "LR.fit(train_bow_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_bow_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=100)\n",
    "LR.fit(train_bow_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_bow_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1000)\n",
    "LR.fit(train_bow_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_bow_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'C' is inversly proportional to 'lamda'.\n",
    "* As 'C' increases, no of non zero's in w will reduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. RandomizedSearchCV_L2-Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=320, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[1,10**4]}\n",
    "param_dist = {'alpha':randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_bow_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RandomizedSearchCV_L1-Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=654, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[10**0, 10**4]}\n",
    "param_dist = {'alpha': randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_bow_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 12057)\n",
      "(3000, 12057)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding weights before applying noise.\n",
    "log_reg_bow_before = SGDClassifier(alpha=0.0001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_bow_before.fit(train_bow_normalize, y_train)\n",
    "#print(log_reg_bow_before.coef_)\n",
    "#--------------------------------------------------------------\n",
    "print(train_bow_normalize.shape)\n",
    "print(test_bow_normalize.shape)\n",
    "#---------------------------------------------------------------\n",
    "#Creating a noise matrix and addingup both,\n",
    "mu, sigma = 0, 0.1 \n",
    "# creating a noise with the same dimension as the dataset \n",
    "train_noise = np.random.normal(mu, sigma, [7000,12057])\n",
    "train_data_noise = train_bow_normalize + train_noise\n",
    "#-----------------------------------------------------------------\n",
    "#Finding weights before applying noise.\n",
    "log_reg_bow_after = SGDClassifier(alpha=0.0001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_bow_after.fit(train_data_noise, y_train)\n",
    "#print(log_reg_bow_after.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264594.42503003316\n"
     ]
    }
   ],
   "source": [
    "diff_coef = (log_reg_bow_before.coef_)-(log_reg_bow_after.coef_)\n",
    "#print(diff_coef)\n",
    "div_coef = diff_coef/(log_reg_bow_before.coef_)\n",
    "per_coef = abs(div_coef) * 100\n",
    "per_mean = np.mean(per_coef)\n",
    "print(per_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** As weight vector values before and after pertubation changes significantly, then we can't use |w| as feature importance measure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0.008846311487409594, 0.0077703992687845865, 0.007452338787385092, 0.006707367381649398, 0.005970118287668688]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "feat_imp = list(model.feature_importances_) #Gives the feature importance scores.\n",
    "print(type(feat_imp))\n",
    "sort_feat_imp = sorted(feat_imp, reverse=True)\n",
    "top_feat_imp = sort_feat_imp[:5]\n",
    "print(top_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.index(0.006707367381649398)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Featurization: Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. GridSearchCV_L2_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.001, average=False, class_weight='balanced',\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8673333333333333\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train and test\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tuned_parameters = [{'alpha':[10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]}]\n",
    "\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidf_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. GridSearchCV_L1_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.83\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with GridSearchCV L-1 Regulizor.\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidf_normalize, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Look at how Sparsity and performance changing for the given C.\n",
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=0.01)\n",
    "LR.fit(train_tfidf_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidf_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=0.1)\n",
    "LR.fit(train_tfidf_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidf_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1.0)\n",
    "LR.fit(train_tfidf_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidf_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=10)\n",
    "LR.fit(train_tfidf_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidf_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=100)\n",
    "LR.fit(train_tfidf_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidf_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1000)\n",
    "LR.fit(train_tfidf_normalize, y_train)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidf_normalize, y_test))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obsevation:**\n",
    "* As 'C' increases, no of non zero's in w will reduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RandomizedSearchCV_L2_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=982, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[1,10**4]}\n",
    "param_dist = {'alpha':randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidf_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RandomizedSearchCV_L1_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=106, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[10**0, 10**4]}\n",
    "param_dist = {'alpha': randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidf_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 12057)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding weights before applying noise.\n",
    "log_reg_tfidf_before = SGDClassifier(alpha=0.001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_tfidf_before.fit(train_bow_normalize, y_train)\n",
    "#print(log_reg_tfidf_before.coef_)\n",
    "#--------------------------------------------------------------\n",
    "print(train_tfidf_normalize.shape)\n",
    "#print(test_tfidf_normalize.shape)\n",
    "#---------------------------------------------------------------\n",
    "#Creating a noise matrix and addingup both,\n",
    "mu, sigma = 0, 0.1 \n",
    "# creating a noise with the same dimension as the dataset \n",
    "train_noise = np.random.normal(mu, sigma, [7000,12057])\n",
    "train_data_noise = train_tfidf_normalize + train_noise\n",
    "#-----------------------------------------------------------------\n",
    "#Finding weights before applying noise.\n",
    "log_reg_tfidf_after = SGDClassifier(alpha=0.001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_tfidf_after.fit(train_data_noise, y_train)\n",
    "#print(log_reg_tfidf_after.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792.7183202856952\n"
     ]
    }
   ],
   "source": [
    "diff_coef = (log_reg_tfidf_before.coef_)-(log_reg_tfidf_after.coef_)\n",
    "#print(diff_coef)\n",
    "div_coef = diff_coef/(log_reg_tfidf_before.coef_)\n",
    "per_coef = abs(div_coef) * 100\n",
    "per_mean = np.mean(per_coef)\n",
    "print(per_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** As weight vector values before and after pertubation changes significantly, then we can't use |w| as feature importance measure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0.012840489354814438, 0.011012369740903407, 0.007936368564732798, 0.007655503374802364, 0.007388203092251884]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "feat_imp = list(model.feature_importances_) #Gives the feature importance scores.\n",
    "print(type(feat_imp))\n",
    "sort_feat_imp = sorted(feat_imp, reverse=True)\n",
    "top_feat_imp = sort_feat_imp[:5]\n",
    "print(top_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11867"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.index(0.007388203092251884)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Avg Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. GridSearchCV_L2_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=100, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train and test\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "tuned_parameters = [{'alpha':[10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]}]\n",
    "\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. GridSearchCV_L1_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=100, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with GridSearchCV L-1 Regulizor.\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Look at how Sparsity and performance changing for the given C or alpha.\n",
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=0.01)\n",
    "LR.fit(train_avgw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_avgw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=0.1)\n",
    "LR.fit(train_avgw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_avgw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1)\n",
    "LR.fit(train_avgw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_avgw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=10)\n",
    "LR.fit(train_avgw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_avgw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=100)\n",
    "LR.fit(train_avgw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_avgw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1000)\n",
    "LR.fit(train_avgw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_avgw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "* As 'C' increases, no of non zero's in w will reduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RandomizedSearchCV_L2_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=220, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[1,10**4]}\n",
    "param_dist = {'alpha':randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RandomizedSearchCV_L1_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=792, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[10**0, 10**4]}\n",
    "param_dist = {'alpha': randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding weights before applying noise.\n",
    "log_reg_avgw2v_before = SGDClassifier(alpha=0.001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_avgw2v_before.fit(train_avgw2v_normalize, y_train_w)\n",
    "#print(log_reg_avgw2v_before.coef_)\n",
    "#--------------------------------------------------------------\n",
    "print(train_avgw2v_normalize.shape)\n",
    "#print(test_avgw2v_normalize.shape)\n",
    "#---------------------------------------------------------------\n",
    "#Creating a noise matrix and addingup both,\n",
    "mu, sigma = 0, 0.1 \n",
    "# creating a noise with the same dimension as the dataset \n",
    "train_noise = np.random.normal(mu, sigma, [7000,300])\n",
    "train_data_noise = train_avgw2v_normalize + train_noise\n",
    "#-----------------------------------------------------------------\n",
    "#Finding weights before applying noise.\n",
    "log_reg_avgw2v_after = SGDClassifier(alpha=0.001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_avgw2v_after.fit(train_data_noise, y_train_w)\n",
    "#print(log_reg_avgw2v_after.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2846.572409658388\n"
     ]
    }
   ],
   "source": [
    "diff_coef = (log_reg_avgw2v_before.coef_)-(log_reg_avgw2v_after.coef_)\n",
    "#print(diff_coef)\n",
    "div_coef = diff_coef/(log_reg_avgw2v_before.coef_)\n",
    "per_coef = abs(div_coef) * 100\n",
    "per_mean = np.mean(per_coef)\n",
    "print(per_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** As weight vector values before and after pertubation changes significantly, then we can't use |w| as feature importance measure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0.008786456609959808, 0.007474162518743816, 0.007096683496718841, 0.006863860288569282, 0.0058719100446479894]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "feat_imp = list(model.feature_importances_) #Gives the feature importance scores.\n",
    "print(type(feat_imp))\n",
    "sort_feat_imp = sorted(feat_imp, reverse=True)\n",
    "top_feat_imp = sort_feat_imp[:5]\n",
    "print(top_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.index(0.0058719100446479894)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization: Tfidf Weighted Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. GridSearchCV_L2_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=100, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Splitting data into train and test\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "tuned_parameters = [{'alpha':[10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]}]\n",
    "\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidfw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. GridSearchCV_L1_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=100, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with GridSearchCV L-1 Regulizor.\n",
    "model = GridSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), tuned_parameters, scoring='accuracy')\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidfw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Look at how Sparsity and performance changing for the given C or alpha.\n",
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=0.01)\n",
    "LR.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidfw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=0.1)\n",
    "LR.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidfw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17033333333333334\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1)\n",
    "LR.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidfw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=10)\n",
    "LR.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidfw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=100)\n",
    "LR.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidfw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296666666666667\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "LR = SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42, alpha=1000)\n",
    "LR.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "w = LR.coef_\n",
    "print(LR.score(test_tfidfw2v_normalize, y_test_w))\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "* As 'C' increases, no of non zero's in w will reduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. RandomizedSearchCV_L2_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=748, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[1,10**4]}\n",
    "param_dist = {'alpha':randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l2', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidfw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. RandomizedSearchCV_L1_Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=318, average=False, class_weight='balanced', epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=None, verbose=0, warm_start=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression with RandamizedSearchCV, Default:L2 reg\n",
    "from scipy.stats import randint\n",
    "#tuned_parameters = {'C':[10**0, 10**4]}\n",
    "param_dist = {'alpha': randint(10**-3,10**3)}\n",
    "model = RandomizedSearchCV(SGDClassifier(class_weight='balanced', penalty='l1', loss='log', random_state=42), param_distributions = param_dist, scoring='accuracy')\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidfw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 300)\n",
      "(3000, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding weights before applying noise.\n",
    "log_reg_tfidfw2v_before = SGDClassifier(alpha=0.001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_tfidfw2v_before.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "#print(log_reg_tfidfw2v_before.coef_)\n",
    "#--------------------------------------------------------------\n",
    "print(train_tfidfw2v_normalize.shape)\n",
    "print(test_tfidfw2v_normalize.shape)\n",
    "#---------------------------------------------------------------\n",
    "#Creating a noise matrix and addingup both,\n",
    "mu, sigma = 0, 0.1 \n",
    "# creating a noise with the same dimension as the dataset \n",
    "train_noise = np.random.normal(mu, sigma, [7000,300])\n",
    "train_data_noise = train_tfidfw2v_normalize + train_noise\n",
    "#-----------------------------------------------------------------\n",
    "#Finding weights before applying noise.\n",
    "log_reg_tfidfw2v_after = SGDClassifier(alpha=0.001, class_weight='balanced', penalty='l2', loss='log', random_state=42)\n",
    "log_reg_tfidfw2v_after.fit(train_data_noise, y_train_w)\n",
    "#print(log_reg_tfidfw2v_after.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292.1420790948361\n"
     ]
    }
   ],
   "source": [
    "diff_coef = (log_reg_tfidfw2v_before.coef_)-(log_reg_tfidfw2v_after.coef_)\n",
    "#print(diff_coef)\n",
    "div_coef = diff_coef/(log_reg_tfidfw2v_before.coef_)\n",
    "per_coef = abs(div_coef) * 100\n",
    "per_mean = np.mean(per_coef)\n",
    "print(per_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** As weight vector values before and after pertubation changes significantly, then we can't use |w| as feature importance measure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0.008784125106847087, 0.006463625321741884, 0.006302503127649487, 0.0055995824361515945, 0.005416648794072623]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "feat_imp = list(model.feature_importances_) #Gives the feature importance scores.\n",
    "print(type(feat_imp))\n",
    "sort_feat_imp = sorted(feat_imp, reverse=True)\n",
    "top_feat_imp = sort_feat_imp[:5]\n",
    "print(top_feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.index(0.005416648794072623)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bow----------------------->alpha=0.0001-------------->Accuracy:87.40%\n",
    "* Tfidf----------------------->alpha=0.001---------------->Accuracy:86.73%\n",
    "* Avg Word2Vec--------->alpha=100------------------->Accuracy:82.96%\n",
    "* Tfidf Word2Vec--------->alpha=100------------------>Accuracy:82.96%\n",
    "* Among all the featurization techniques, we are getting slightly better accuracy with Bag of words featurization\n",
    "* Logistic regression works very well for the higher dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
