{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM on Amazon Food Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet Source: https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing all Necessory Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Bow data:\n",
    "import pickle\n",
    "with open('train_bow.pickle','rb') as handle:\n",
    "    train_bow = pickle.load(handle)\n",
    "with open('test_bow.pickle','rb') as handle:\n",
    "    test_bow = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Tfidf data:\n",
    "import pickle\n",
    "with open('train_tfidf.pickle','rb') as handle:\n",
    "    train_tfidf = pickle.load(handle)\n",
    "with open('test_tfidf.pickle','rb') as handle:\n",
    "    test_tfidf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg Word2Vec data:\n",
    "import pickle\n",
    "with open('train_avg_word2vec.pickle','rb') as handle:\n",
    "    train_avg_word2vec = pickle.load(handle)\n",
    "with open('test_avg_word2vec.pickle','rb') as handle:\n",
    "    test_avg_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loding Avg Word2Vec data:\n",
    "import pickle\n",
    "with open('train_tfidf_word2vec.pickle','rb') as handle:\n",
    "    train_tfidf_word2vec = pickle.load(handle)\n",
    "with open('test_tfidf_word2vec.pickle','rb') as handle:\n",
    "    test_tfidf_word2vec = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('y_train.pickle','rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "with open('y_test.pickle','rb') as handle:\n",
    "    y_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('y_train_w.pickle','rb') as handle:\n",
    "    y_train_w = pickle.load(handle)\n",
    "with open('y_test_w.pickle','rb') as handle:\n",
    "    y_test_w = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "#Normalizing each feature.\n",
    "#After normalization,all the feature values lies between 0 and 1.\n",
    "#Bow features\n",
    "train_bow_normalize = normalize(train_bow, axis=0)\n",
    "test_bow_normalize = normalize(test_bow, axis=0)\n",
    "#Tfidf features\n",
    "train_tfidf_normalize = normalize(train_tfidf, axis=0)\n",
    "test_tfidf_normalize = normalize(test_tfidf, axis=0)\n",
    "#Avg word2vec features\n",
    "train_avgw2v_normalize = normalize(train_avg_word2vec, axis=0)\n",
    "test_avgw2v_normalize = normalize(test_avg_word2vec, axis=0)\n",
    "#Tfidf weighted word2vec features\n",
    "train_tfidfw2v_normalize = normalize(train_tfidf_word2vec, axis=0)\n",
    "test_tfidfw2v_normalize = normalize(test_tfidf_word2vec, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization:Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8343333333333334\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'C':[10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]}, {'gamma':[10**-2, 10**-1, 10**0, 10**1, 10**2]}]\n",
    "#Default RBF kernal.\n",
    "model = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_bow_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=547, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.833\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "tuned_parameters = {'C':randint(10**-3, 10**3), 'gamma':randint(10**-2, 10**2)}\n",
    "#Default RBF Kernal.\n",
    "model = RandomizedSearchCV(SVC(), param_distributions = tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_bow_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_bow_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization:Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.832\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'C':[10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]}, {'gamma':[10**-2, 10**-1, 10**0, 10**1, 10**2]}]\n",
    "#Default RBF kernal.\n",
    "model = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidf_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=296, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=53, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "tuned_parameters = {'C':randint(10**-3, 10**3), 'gamma':randint(10**-2, 10**2)}\n",
    "#Default RBF Kernal.\n",
    "model = RandomizedSearchCV(SVC(), param_distributions = tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_tfidf_normalize, y_train)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidf_normalize, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization:Avg Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=100, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'C':[10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]}, {'gamma':[10**-2, 10**-1, 10**0, 10**1, 10**2]}]\n",
    "#Default RBF kernal.\n",
    "model = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=91, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=83, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "tuned_parameters = {'C':randint(10**-3, 10**3), 'gamma':randint(10**-2, 10**2)}\n",
    "#Default RBF Kernal.\n",
    "model = RandomizedSearchCV(SVC(), param_distributions = tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_avgw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization:Tfidf Weighted Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=100, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "tuned_parameters = [{'C':[10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3]}, {'gamma':[10**-2, 10**-1, 10**0, 10**1, 10**2]}]\n",
    "#Default RBF kernal.\n",
    "model = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_avgw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=11, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=6, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8296666666666667\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameter tuning with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "tuned_parameters = {'C':randint(10**-3, 10**3), 'gamma':randint(10**-2, 10**2)}\n",
    "#Default RBF Kernal.\n",
    "model = RandomizedSearchCV(SVC(), param_distributions = tuned_parameters, scoring='accuracy',n_jobs=-1)\n",
    "model.fit(train_tfidfw2v_normalize, y_train_w)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(test_tfidfw2v_normalize, y_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bag of Words(BOW)------------->C(HyperParameter)=1 ------->Acc=83.4%\n",
    "* Term Frequency_Inverse Document frequency(TFIDF)----->C=1 ------->Acc=83.2%\n",
    "* Average Word2Vec---------------->C=1 ------------->Acc=82.9%\n",
    "* Tfidf Weighted Word2Vec------------>C=1 -------->Acc=82.9%\n",
    "* Bag of words featurization gives best Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
